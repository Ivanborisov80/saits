{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#from tsdb import pickle_dump\n",
    "import argparse\n",
    "from unified_dataloader import UnifiedDataLoader\n",
    "from saitsd import SAITS\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from data_processing_utils import (\n",
    "    window_truncate,\n",
    "    random_mask,\n",
    "    add_artificial_mask,\n",
    "    saving_into_h5,\n",
    ")\n",
    "from datetime import datetime\n",
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "log(): argument 'input' (position 1) must be Tensor, not float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/r5/41tjk6310pg5lnjnx7_q2dm40000gn/T/ipykernel_82562/410718421.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlog_likelihood\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msigma\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtotal_log_likelihood\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_likelihood\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: log(): argument 'input' (position 1) must be Tensor, not float"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = torch.tensor([1.0,2.0],requires_grad=True)\n",
    "sigma = torch.tensor([1.0,2.0],requires_grad=True)\n",
    "target= torch.tensor([1.0,2.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DICT = {\n",
    "    # Self-Attention (SA) based\n",
    "   \n",
    "    \"SAITS\": SAITS,\n",
    "    # RNN based\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def ornstein_uhlenbeck(x0, theta, mu, sigma, dt, num_steps, num_samples):\n",
    "    x = np.zeros((num_steps, num_samples))\n",
    "    x[0] = x0\n",
    "    for t in range(1, num_steps):\n",
    "        if t<7:\n",
    "            x[t] = x[t-1] + theta * (mu - x[t-1]) * dt + sigma * np.sqrt(dt) * np.ones(num_samples)\n",
    "        else:\n",
    "            x[t] = x[t-1] + theta * (mu - x[t-1]) * dt + sigma * np.sqrt(dt) * np.random.normal(num_samples)\n",
    "    return x\n",
    "\n",
    "# Parameters\n",
    "x0 = 0  # Initial value\n",
    "theta = 0.1  # Rate of reversion\n",
    "mu = 0.5  # Long-term mean\n",
    "sigma = 0.3  # Volatility\n",
    "dt = 0.01  # Time step\n",
    "num_steps = 8  # Number of steps\n",
    "num_samples =45 # Number of samples at each step\n",
    "\n",
    "# Simulate Ornstein-Uhlenbeck process\n",
    "ou_process = ornstein_uhlenbeck(x0, theta, mu, sigma, dt, num_steps, num_samples)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    " # volatility\n",
    "delta_t = 1  # time step size\n",
    "\n",
    "\n",
    "\n",
    "dt = delta_t\n",
    "mean = ou_process[6, :] * np.exp(-theta * dt) + mu * (1 - np.exp(-theta * dt))\n",
    "variance = (sigma**2 / (2 * theta)) * (1 - np.exp(-2 * theta * dt))\n",
    "ou_process[7, :] = mean + np.random.normal(0, np.sqrt(variance), num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty=np.empty(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(45):\n",
    "    mean=np.repeat(ou_process[7, i] * np.exp(-theta * dt) + mu * (1 - np.exp(-theta * dt)),45)\n",
    "    variance = np.repeat((sigma**2 / (2 * theta)) * (1 - np.exp(-2 * theta * dt)),45)\n",
    "   \n",
    "    ou_new=mean + np.random.normal(0, np.sqrt(variance),num_samples)\n",
    "    empty=np.append(empty,ou_new)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.32801771,  0.39889443, -0.24801868, ...,  0.27618894,\n",
       "        0.16236607,  0.66707857])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(ou_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    # Duplicate the current column 50 times and add to the result DataFrame\n",
    "    duplicated_columns = pd.concat([df[col]] * 45, axis=1)\n",
    "    # Rename the columns to indicate their original name and index\n",
    "    duplicated_columns.columns = [f'{col}_{i+1}' for i in range(45)]\n",
    "    # Append to the result DataFrame\n",
    "    result_df = pd.concat([result_df, duplicated_columns], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = result_df.append(pd.Series(empty, index=result_df.columns), ignore_index=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_1</th>\n",
       "      <th>0_2</th>\n",
       "      <th>0_3</th>\n",
       "      <th>0_4</th>\n",
       "      <th>0_5</th>\n",
       "      <th>0_6</th>\n",
       "      <th>0_7</th>\n",
       "      <th>0_8</th>\n",
       "      <th>0_9</th>\n",
       "      <th>0_10</th>\n",
       "      <th>...</th>\n",
       "      <th>44_36</th>\n",
       "      <th>44_37</th>\n",
       "      <th>44_38</th>\n",
       "      <th>44_39</th>\n",
       "      <th>44_40</th>\n",
       "      <th>44_41</th>\n",
       "      <th>44_42</th>\n",
       "      <th>44_43</th>\n",
       "      <th>44_44</th>\n",
       "      <th>44_45</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.030500</td>\n",
       "      <td>0.030500</td>\n",
       "      <td>0.030500</td>\n",
       "      <td>0.030500</td>\n",
       "      <td>0.030500</td>\n",
       "      <td>0.030500</td>\n",
       "      <td>0.030500</td>\n",
       "      <td>0.030500</td>\n",
       "      <td>0.030500</td>\n",
       "      <td>0.030500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030500</td>\n",
       "      <td>0.030500</td>\n",
       "      <td>0.030500</td>\n",
       "      <td>0.030500</td>\n",
       "      <td>0.030500</td>\n",
       "      <td>0.030500</td>\n",
       "      <td>0.030500</td>\n",
       "      <td>0.030500</td>\n",
       "      <td>0.030500</td>\n",
       "      <td>0.030500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.060969</td>\n",
       "      <td>0.060969</td>\n",
       "      <td>0.060969</td>\n",
       "      <td>0.060969</td>\n",
       "      <td>0.060969</td>\n",
       "      <td>0.060969</td>\n",
       "      <td>0.060969</td>\n",
       "      <td>0.060969</td>\n",
       "      <td>0.060969</td>\n",
       "      <td>0.060969</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060969</td>\n",
       "      <td>0.060969</td>\n",
       "      <td>0.060969</td>\n",
       "      <td>0.060969</td>\n",
       "      <td>0.060969</td>\n",
       "      <td>0.060969</td>\n",
       "      <td>0.060969</td>\n",
       "      <td>0.060969</td>\n",
       "      <td>0.060969</td>\n",
       "      <td>0.060969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.091409</td>\n",
       "      <td>0.091409</td>\n",
       "      <td>0.091409</td>\n",
       "      <td>0.091409</td>\n",
       "      <td>0.091409</td>\n",
       "      <td>0.091409</td>\n",
       "      <td>0.091409</td>\n",
       "      <td>0.091409</td>\n",
       "      <td>0.091409</td>\n",
       "      <td>0.091409</td>\n",
       "      <td>...</td>\n",
       "      <td>0.091409</td>\n",
       "      <td>0.091409</td>\n",
       "      <td>0.091409</td>\n",
       "      <td>0.091409</td>\n",
       "      <td>0.091409</td>\n",
       "      <td>0.091409</td>\n",
       "      <td>0.091409</td>\n",
       "      <td>0.091409</td>\n",
       "      <td>0.091409</td>\n",
       "      <td>0.091409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.121817</td>\n",
       "      <td>0.121817</td>\n",
       "      <td>0.121817</td>\n",
       "      <td>0.121817</td>\n",
       "      <td>0.121817</td>\n",
       "      <td>0.121817</td>\n",
       "      <td>0.121817</td>\n",
       "      <td>0.121817</td>\n",
       "      <td>0.121817</td>\n",
       "      <td>0.121817</td>\n",
       "      <td>...</td>\n",
       "      <td>0.121817</td>\n",
       "      <td>0.121817</td>\n",
       "      <td>0.121817</td>\n",
       "      <td>0.121817</td>\n",
       "      <td>0.121817</td>\n",
       "      <td>0.121817</td>\n",
       "      <td>0.121817</td>\n",
       "      <td>0.121817</td>\n",
       "      <td>0.121817</td>\n",
       "      <td>0.121817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.152195</td>\n",
       "      <td>0.152195</td>\n",
       "      <td>0.152195</td>\n",
       "      <td>0.152195</td>\n",
       "      <td>0.152195</td>\n",
       "      <td>0.152195</td>\n",
       "      <td>0.152195</td>\n",
       "      <td>0.152195</td>\n",
       "      <td>0.152195</td>\n",
       "      <td>0.152195</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152195</td>\n",
       "      <td>0.152195</td>\n",
       "      <td>0.152195</td>\n",
       "      <td>0.152195</td>\n",
       "      <td>0.152195</td>\n",
       "      <td>0.152195</td>\n",
       "      <td>0.152195</td>\n",
       "      <td>0.152195</td>\n",
       "      <td>0.152195</td>\n",
       "      <td>0.152195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.182543</td>\n",
       "      <td>0.182543</td>\n",
       "      <td>0.182543</td>\n",
       "      <td>0.182543</td>\n",
       "      <td>0.182543</td>\n",
       "      <td>0.182543</td>\n",
       "      <td>0.182543</td>\n",
       "      <td>0.182543</td>\n",
       "      <td>0.182543</td>\n",
       "      <td>0.182543</td>\n",
       "      <td>...</td>\n",
       "      <td>0.182543</td>\n",
       "      <td>0.182543</td>\n",
       "      <td>0.182543</td>\n",
       "      <td>0.182543</td>\n",
       "      <td>0.182543</td>\n",
       "      <td>0.182543</td>\n",
       "      <td>0.182543</td>\n",
       "      <td>0.182543</td>\n",
       "      <td>0.182543</td>\n",
       "      <td>0.182543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.099839</td>\n",
       "      <td>0.099839</td>\n",
       "      <td>0.099839</td>\n",
       "      <td>0.099839</td>\n",
       "      <td>0.099839</td>\n",
       "      <td>0.099839</td>\n",
       "      <td>0.099839</td>\n",
       "      <td>0.099839</td>\n",
       "      <td>0.099839</td>\n",
       "      <td>0.099839</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146144</td>\n",
       "      <td>0.146144</td>\n",
       "      <td>0.146144</td>\n",
       "      <td>0.146144</td>\n",
       "      <td>0.146144</td>\n",
       "      <td>0.146144</td>\n",
       "      <td>0.146144</td>\n",
       "      <td>0.146144</td>\n",
       "      <td>0.146144</td>\n",
       "      <td>0.146144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.328018</td>\n",
       "      <td>0.398894</td>\n",
       "      <td>-0.248019</td>\n",
       "      <td>0.107327</td>\n",
       "      <td>-0.089095</td>\n",
       "      <td>-0.207869</td>\n",
       "      <td>0.307163</td>\n",
       "      <td>-0.381622</td>\n",
       "      <td>0.042165</td>\n",
       "      <td>0.071697</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.153329</td>\n",
       "      <td>0.110759</td>\n",
       "      <td>0.507117</td>\n",
       "      <td>0.687423</td>\n",
       "      <td>0.159373</td>\n",
       "      <td>0.122078</td>\n",
       "      <td>0.334667</td>\n",
       "      <td>0.276189</td>\n",
       "      <td>0.162366</td>\n",
       "      <td>0.667079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows Ã— 2025 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0_1       0_2       0_3       0_4       0_5       0_6       0_7  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.030500  0.030500  0.030500  0.030500  0.030500  0.030500  0.030500   \n",
       "2  0.060969  0.060969  0.060969  0.060969  0.060969  0.060969  0.060969   \n",
       "3  0.091409  0.091409  0.091409  0.091409  0.091409  0.091409  0.091409   \n",
       "4  0.121817  0.121817  0.121817  0.121817  0.121817  0.121817  0.121817   \n",
       "5  0.152195  0.152195  0.152195  0.152195  0.152195  0.152195  0.152195   \n",
       "6  0.182543  0.182543  0.182543  0.182543  0.182543  0.182543  0.182543   \n",
       "7  0.099839  0.099839  0.099839  0.099839  0.099839  0.099839  0.099839   \n",
       "8 -0.328018  0.398894 -0.248019  0.107327 -0.089095 -0.207869  0.307163   \n",
       "\n",
       "        0_8       0_9      0_10  ...     44_36     44_37     44_38     44_39  \\\n",
       "0  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.030500  0.030500  0.030500  ...  0.030500  0.030500  0.030500  0.030500   \n",
       "2  0.060969  0.060969  0.060969  ...  0.060969  0.060969  0.060969  0.060969   \n",
       "3  0.091409  0.091409  0.091409  ...  0.091409  0.091409  0.091409  0.091409   \n",
       "4  0.121817  0.121817  0.121817  ...  0.121817  0.121817  0.121817  0.121817   \n",
       "5  0.152195  0.152195  0.152195  ...  0.152195  0.152195  0.152195  0.152195   \n",
       "6  0.182543  0.182543  0.182543  ...  0.182543  0.182543  0.182543  0.182543   \n",
       "7  0.099839  0.099839  0.099839  ...  0.146144  0.146144  0.146144  0.146144   \n",
       "8 -0.381622  0.042165  0.071697  ... -0.153329  0.110759  0.507117  0.687423   \n",
       "\n",
       "      44_40     44_41     44_42     44_43     44_44     44_45  \n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1  0.030500  0.030500  0.030500  0.030500  0.030500  0.030500  \n",
       "2  0.060969  0.060969  0.060969  0.060969  0.060969  0.060969  \n",
       "3  0.091409  0.091409  0.091409  0.091409  0.091409  0.091409  \n",
       "4  0.121817  0.121817  0.121817  0.121817  0.121817  0.121817  \n",
       "5  0.152195  0.152195  0.152195  0.152195  0.152195  0.152195  \n",
       "6  0.182543  0.182543  0.182543  0.182543  0.182543  0.182543  \n",
       "7  0.146144  0.146144  0.146144  0.146144  0.146144  0.146144  \n",
       "8  0.159373  0.122078  0.334667  0.276189  0.162366  0.667079  \n",
       "\n",
       "[9 rows x 2025 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3280566451599556, 0.3067730689596443)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm.fit(ou_process[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=result_df.T.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.0305    ,  0.0609695 , ...,  0.18254311,\n",
       "         0.09983927, -0.32801771],\n",
       "       [ 0.        ,  0.0305    ,  0.0609695 , ...,  0.18254311,\n",
       "         0.09983927,  0.39889443],\n",
       "       [ 0.        ,  0.0305    ,  0.0609695 , ...,  0.18254311,\n",
       "         0.09983927, -0.24801868],\n",
       "       ...,\n",
       "       [ 0.        ,  0.0305    ,  0.0609695 , ...,  0.18254311,\n",
       "         0.14614433,  0.27618894],\n",
       "       [ 0.        ,  0.0305    ,  0.0609695 , ...,  0.18254311,\n",
       "         0.14614433,  0.16236607],\n",
       "       [ 0.        ,  0.0305    ,  0.0609695 , ...,  0.18254311,\n",
       "         0.14614433,  0.66707857]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.reshape(2025,9,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_X=data[:1700]\n",
    "test_set_X=data[1700:1800]\n",
    "val_set_X=data[1800:2025]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_dict = add_artificial_mask(\n",
    "        train_set_X, 0.1, \"train\"\n",
    "    )\n",
    "val_set_dict = add_artificial_mask(val_set_X, 0.1, \"val\")\n",
    "test_set_dict = add_artificial_mask(\n",
    "        test_set_X, 0.1, \"test\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = {\n",
    "        \"train\": train_set_dict,\n",
    "        \"val\":val_set_dict,\n",
    "        \"test\": test_set_dict,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "saving_dir='/Users/ivan/Downloads'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'saving_into_h5' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/r5/41tjk6310pg5lnjnx7_q2dm40000gn/T/ipykernel_80419/1092660933.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msaving_into_h5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocessed_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassification_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'saving_into_h5' is not defined"
     ]
    }
   ],
   "source": [
    "saving_into_h5(saving_dir, processed_data, classification_dataset=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from configparser import ConfigParser, ExtendedInterpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = ConfigParser(interpolation=ExtendedInterpolation())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_arguments(arg_parser, cfg_parser):\n",
    "    # file path\n",
    "    arg_parser.dataset_base_dir = cfg_parser.get(\"file_path\", \"dataset_base_dir\")\n",
    "    \n",
    "    # dataset info\n",
    "    arg_parser.seq_len = cfg_parser.getint(\"dataset\", \"seq_len\")\n",
    "    arg_parser.batch_size = cfg_parser.getint(\"dataset\", \"batch_size\")\n",
    "    arg_parser.num_workers = cfg_parser.getint(\"dataset\", \"num_workers\")\n",
    "    arg_parser.feature_num = cfg_parser.getint(\"dataset\", \"feature_num\")\n",
    "    arg_parser.dataset_name = cfg_parser.get(\"dataset\", \"dataset_name\")\n",
    "    arg_parser.dataset_path = os.path.join(\n",
    "        arg_parser.dataset_base_dir, arg_parser.dataset_name\n",
    "    )\n",
    "    arg_parser.eval_every_n_steps = cfg_parser.getint(\"dataset\", \"eval_every_n_steps\")\n",
    "    # training settings\n",
    "    arg_parser.MIT = cfg_parser.getboolean(\"training\", \"MIT\")\n",
    "    arg_parser.ORT = cfg_parser.getboolean(\"training\", \"ORT\")\n",
    "    arg_parser.lr = cfg_parser.getfloat(\"training\", \"lr\")\n",
    "    arg_parser.optimizer_type = cfg_parser.get(\"training\", \"optimizer_type\")\n",
    "    arg_parser.weight_decay = cfg_parser.getfloat(\"training\", \"weight_decay\")\n",
    "    arg_parser.device = cfg_parser.get(\"training\", \"device\")\n",
    "    arg_parser.epochs = cfg_parser.getint(\"training\", \"epochs\")\n",
    "    arg_parser.early_stop_patience = cfg_parser.getint(\n",
    "        \"training\", \"early_stop_patience\"\n",
    "    )\n",
    "    \n",
    "    arg_parser.max_norm = cfg_parser.getfloat(\"training\", \"max_norm\")\n",
    "    arg_parser.imputation_loss_weight = cfg_parser.getfloat(\n",
    "        \"training\", \"imputation_loss_weight\"\n",
    "    )\n",
    "    arg_parser.reconstruction_loss_weight = cfg_parser.getfloat(\n",
    "        \"training\", \"reconstruction_loss_weight\"\n",
    "    )\n",
    "    # model settings\n",
    "    arg_parser.model_name = cfg_parser.get(\"model\", \"model_name\")\n",
    "    arg_parser.model_type = cfg_parser.get(\"model\", \"model_type\")\n",
    "    return arg_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--config_path'], dest='config_path', nargs=None, const=None, default='/Users/ivan/Desktop/saits/AirQuality_SAITS_best.ini', type=<class 'str'>, choices=None, help='path of config file', metavar=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--config_path\", type=str, help=\"path of config file\",default=\"/Users/ivan/Desktop/saits/AirQuality_SAITS_best.ini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "args,unknown = parser.parse_known_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(config_path='/Users/ivan/Desktop/saits/AirQuality_SAITS_best.ini')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/ivan/Desktop/saits/AirQuality_SAITS_best.ini']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.read(args.config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = read_arguments(args, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(config_path='/Users/ivan/Desktop/saits/AirQuality_SAITS_best.ini', dataset_base_dir='generated_datasets', seq_len=9, batch_size=128, num_workers=4, feature_num=1, dataset_name='AirQuality_seqlen24_01masked', dataset_path='generated_datasets/AirQuality_seqlen24_01masked', eval_every_n_steps=7, MIT=True, ORT=True, lr=0.0008821387950693266, optimizer_type='adam', weight_decay=0.0, device='cuda', epochs=10000, early_stop_patience=30, max_norm=0.0, imputation_loss_weight=1.0, reconstruction_loss_weight=1.0, model_name='AirQuality_SAITS_best', model_type='SAITS')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.model_type in [\"Transformer\", \"SAITS\"]:  # if SA-based model\n",
    "        args.input_with_mask = cfg.getboolean(\"model\", \"input_with_mask\")\n",
    "        args.n_groups = cfg.getint(\"model\", \"n_groups\")\n",
    "        args.n_group_inner_layers = cfg.getint(\"model\", \"n_group_inner_layers\")\n",
    "        args.param_sharing_strategy = cfg.get(\"model\", \"param_sharing_strategy\")\n",
    "        assert args.param_sharing_strategy in [\n",
    "            \"inner_group\",\n",
    "            \"between_group\",\n",
    "        ], 'only \"inner_group\"/\"between_group\" sharing'\n",
    "        args.d_model = cfg.getint(\"model\", \"d_model\")\n",
    "        args.d_inner = cfg.getint(\"model\", \"d_inner\")\n",
    "        args.n_head = cfg.getint(\"model\", \"n_head\")\n",
    "        args.d_k = cfg.getint(\"model\", \"d_k\")\n",
    "        args.d_v = cfg.getint(\"model\", \"d_v\")\n",
    "        args.dropout = cfg.getfloat(\"model\", \"dropout\")\n",
    "        args.diagonal_attention_mask = cfg.getboolean(\n",
    "            \"model\", \"diagonal_attention_mask\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_args = vars(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = {\n",
    "            \"device\":'cpu',\n",
    "            \"MIT\": args.MIT,\n",
    "            # imputer args\n",
    "            \"n_groups\": dict_args[\"n_groups\"],\n",
    "            \"n_group_inner_layers\": args.n_group_inner_layers,\n",
    "            \"d_time\": args.seq_len,\n",
    "            \"d_feature\": args.feature_num,\n",
    "            \"dropout\": dict_args[\"dropout\"],\n",
    "            \"d_model\": dict_args[\"d_model\"],\n",
    "            \"d_inner\": dict_args[\"d_inner\"],\n",
    "            \"n_head\": dict_args[\"n_head\"],\n",
    "            \"d_k\": dict_args[\"d_k\"],\n",
    "            \"d_v\": dict_args[\"d_v\"],\n",
    "            \"input_with_mask\": args.input_with_mask,\n",
    "            \"diagonal_attention_mask\": args.diagonal_attention_mask,\n",
    "            \"param_sharing_strategy\": args.param_sharing_strategy,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_now = datetime.now().__format__(\"%Y-%m-%d_T%H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "unified_dataloader = UnifiedDataLoader(\n",
    "        saving_dir,\n",
    "        args.seq_len,\n",
    "        1,\n",
    "        args.model_type,\n",
    "        args.batch_size,\n",
    "        args.num_workers,\n",
    "        args.MIT,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader,val_dataloader= unified_dataloader.get_train_val_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x110dfd700>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MODEL_DICT[args.model_type](**model_args)\n",
    "OPTIMIZER = {\"adam\": torch.optim.Adam, \"adamw\": torch.optim.AdamW}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices, X, missing_mask, X_holdout, indicating_mask = map(\n",
    "                    lambda x: x.to('cpu'),next(iter(train_dataloader))\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\n",
    "                    \"indices\": indices,\n",
    "                    \"X\": X,\n",
    "                    \"missing_mask\": missing_mask,\n",
    "                    \"X_holdout\": X_holdout,\n",
    "                    \"indicating_mask\": indicating_mask,\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_processing(results):\n",
    "    \"\"\"process results and losses for each training step\"\"\"\n",
    "    results[\"total_loss\"] = torch.tensor(0.0, device=args.device)\n",
    "    if args.MIT:\n",
    "        results[\"total_loss\"] += results[\"imputation_loss\"]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_each_training_step(\n",
    "    results, optimizer\n",
    "):\n",
    "    \"\"\"process each training step and return whether to early stop\"\"\"\n",
    "  \n",
    "    # apply gradient clipping if args.max_norm != 0\n",
    "    if args.max_norm != 0:\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=args.max_norm)\n",
    "    results[\"total_loss\"].backward()\n",
    "    optimizer.step()\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_processing(\n",
    "    data,\n",
    "    model,\n",
    "    stage,\n",
    "    # following arguments are only required in the training stage\n",
    "    optimizer=None,\n",
    "    val_dataloader=None,\n",
    " \n",
    "    training_controller=None,\n",
    "    logger=None,\n",
    "):\n",
    "    if stage == \"train\":\n",
    "        optimizer.zero_grad()\n",
    "        if not args.MIT:\n",
    "              # then for self-attention based models, i.e. Transformer/SAITS\n",
    "                indices, X, missing_mask = map(lambda x: x.to(args.device), data)\n",
    "                inputs = {\"indices\": indices, \"X\": X, \"missing_mask\": missing_mask}\n",
    "                results = result_processing(model(inputs, stage))\n",
    "                early_stopping = process_each_training_step(\n",
    "                results,\n",
    "                optimizer,\n",
    "                val_dataloader,\n",
    "                training_controller,\n",
    "\n",
    "            )\n",
    "        else:\n",
    "            \n",
    "                \n",
    "                indices, X, missing_mask, X_holdout, indicating_mask = map(\n",
    "                    lambda x: x.to('cpu'), data\n",
    "                    )\n",
    "                for idx in range(7,9):\n",
    "                    inputs = {\"indices\": indices, \"X\": X, \"missing_mask\": missing_mask,\"X_holdout\":X_holdout,\"indicating_mask\":indicating_mask,\"idx\":idx}\n",
    "                    \n",
    "                    results = result_processing(model(inputs, stage))\n",
    "                    X[:,idx,:]=X_holdout[:,idx,:]\n",
    "                    missing_mask[:,idx,:]=1\n",
    "                    early_stopping = process_each_training_step(\n",
    "                    results,\n",
    "                    optimizer\n",
    "                    )\n",
    "        return early_stopping\n",
    "    return inputs, results\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model,\n",
    "    optimizer,\n",
    "    train_dataloader\n",
    "):\n",
    "    for epoch in range(args.epochs):\n",
    "        early_stopping = False\n",
    "        args.final_epoch = True if epoch == args.epochs - 1 else False\n",
    "        for idx, data in enumerate(train_dataloader):\n",
    "            model.train()\n",
    "            early_stopping = model_processing(\n",
    "                data,\n",
    "                model,\n",
    "                \"train\",\n",
    "                optimizer\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(config_path='/Users/ivan/Desktop/saits/AirQuality_SAITS_best.ini', dataset_base_dir='generated_datasets', seq_len=9, batch_size=128, num_workers=4, feature_num=1, dataset_name='AirQuality_seqlen24_01masked', dataset_path='generated_datasets/AirQuality_seqlen24_01masked', eval_every_n_steps=7, MIT=True, ORT=True, lr=0.0008821387950693266, optimizer_type='adam', weight_decay=0.0, device='cuda', epochs=10000, early_stop_patience=30, max_norm=0.0, imputation_loss_weight=1.0, reconstruction_loss_weight=1.0, model_name='AirQuality_SAITS_best', model_type='SAITS', input_with_mask=True, n_groups=1, n_group_inner_layers=1, param_sharing_strategy='inner_group', d_model=32, d_inner=32, n_head=4, d_k=128, d_v=64, dropout=0.0, diagonal_attention_mask=True, final_epoch=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = OPTIMIZER[args.optimizer_type](\n",
    "            model.parameters(), lr=dict_args[\"lr\"], weight_decay=args.weight_decay\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "train(\n",
    "            model,\n",
    "            optimizer,\n",
    "            train_dataloader\n",
    "        )\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
